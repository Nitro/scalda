Acquisition in Autoshaping 
Sham Kakade Peter Dayan 
Gatsby Computational Neuroscience Unit 
17 Queen Square, London, England, WC1N 3AR. 
sham@gatsby. ucl. ac. uk dayan@gatsby. ucl. ac. uk 
Abstract 
Quantitative data on the speed with which animals acquire behav- 
ioral responses during classical conditioning experiments should 
provide strong constraints on models of learning. However, most 
models have simply ignored these data; the few that have attempt- 
ed to address them have failed by at least an order of magnitude. 
We discuss key data on the speed of acquisition, and show how to 
account for them using a statistically sound model of learning, in 
which differential reliabilities of stimuli play a crucial role. 
1 Introduction 
Conditioning experiments probe the ways that animals make predictions about 
rewards and punishments and how those predictions are used to their advantage. 
Substantial quantitative data are available as to how pigeons and rats acquire con- 
ditioned responses during autoshaping, which is one of the simplest paradigTns 
of classical conditioning. 4 These data are revealing about the statistical, and ulti- 
mately also the neural, substrate underlying the ways that animals learn about the 
causal texture of their environments. 
In autoshaping experiments on pigeons, the birds acquire a peck response to a 
lighted key associated (irrespective of their actions) with the delivery of food. One 
attractive feature of autoshaping is that there is no need for separate 'probe trials' 
to assess the degree of association formed between the light and the food by the 
animal rather, the rate of key pecking during the light (and before the food) can 
be used as a direct measure of this association. In particular, acquisition speeds are 
often measured by the number of trials until a certain behavioral criterion is met, 
such as pecking during the light on three out of four successive trials. a, 8' 0 
As stressed persuasively by Gallistel & Gibbon 4 (GG; forthcoming), the critical 
feature of autoshaping is that there is substantial experimental evidence on how 
acquisition speed depends on the three critical variables shown in figure 1A. The 
first is l, the inter-trial interval; the second is T, the time during the trial for which 
the light is presented; the third is the training schedule, l/S, which is the fractional 
number of deliveries per light -- some birds were only partially reinforced. 
Figure 1 makes three key points. First, figure lB shows that the median number of 
trials to the acquisition criterion depends on the ratio of I/T, and not on I and T 
separately - experiments reporte d for the same I/2 are actually performed with l 
and T differing by more than an order of magnitude? 8 Second, figure lB shows 
convincingly that the number of reinforcements is approximately inversely pro- 
portional to I/2 the relatively shorter presentation of light, the faster the learn- 
Acquisition in Autoshaping 25 
A B  
light  
\ /x time -' 
reward S = 2 
time 
1 2 5 10 20 50 
I/T 
10o00 
lO 2 3 4 5 lO 
s 
Figure 1: Autoshaping. A) Experimental paradigm. Top: the light is presented for T seconds every C 
seconds and is always followed by the delivery of food (filled circle). Bottom: the food is delivered with 
probability 1IS = 1/2 per trial. In some cases I is stochastic, with the appropriate mean. B) Log-log 
plot 4 of the number of reinforcements to a given acquisition criterion versus the I/T ratio for S = 1. 
The data are median acquisition times from 12 different laboratories. C) Log-log acquisition curves for 
various I/T ratios and S values. The main graph shows trials versus S; the inset shows reinforcements 
versus S. (1999). 
ing. Third, figure 1C shows that partial reinforcement has almost no effect when 
measured as a function of the number of reinforcements (rather than the number 
of trials), 4' 0 since although it takes $ times as many trials to acquire, there are rein- 
forcements on only 1/S trials. Changing $ does not change the effective I/T when 
measured as a function of reinforcements, so this result might actually be expected 
on the basis of figure lB, and we only consider S = 1 in this paper. Altogether, the 
data show that: 
n  300 * T/I (1) 
where n is the number of rewards to the acquisition criterion. Remarkably, these 
effects seem to hold for over an order of magnitude in both I/T and S. 
These quantitative data should be a most seductive target for statistically sound 
models of learning. However, few models have even attempted to capture the 
strong constraints they provide, and those that have attempted, all fail in critical 
aspects. The best of them, rate estimation theory 4 (RET), is closely related to the 
Rescorla-Wagner 13 (RW) model, and actually captures the proportionality in equa- 
tion 1. However, as shown below, RET grossly overestimates the observed speed 
of acquisition (underestimating the proportionality constant). Further, RET is de- 
signed to account for the time at which a particular, standard, acquisition criterion 
is met. Figure 2A shows that this is revealing only about the very early stages of 
learning -- RET is silent about the remainder of the learning curve. 
We look at additional quantitative data on learning, which collectively suggest 
that stimuli compete to predict the delivery of reward. Dayan & Long 3 (DL) dis- 
cussed various statistically inspired competitive models of classical conditioning, 
concluding with one in which stimuli are differently reliable as predictors of re- 
ward. However, DL ignored the data shown in figures 1 and 2, basing their anal- 
ysis on conditioning paradigms in which I/T was not a factor. Figures 1 and 2 
demand a more sophisticated statistical model -- building such a model is the 
focus of this paper. 
2 Rate Estimation Theory 
Gallistel & Gibbon 4 (GG; forthcoming) are amongst the strongest proponents of the 
quantitative relationships in figure 1. To account for them, GG suggest that animals 
are estimating the rates of rewards -- one, ,Xt, for the rate associated with the light 
and another, ,Xb, for the rate associated with the background context. The context is 
the ever-present environment which can itself gain associative value. The overall 
26 S. Kakade and P Dayan 
0.5 
r- 14o 
B 
o 
.120 
_o 80 
 6o 
E 
�, 40 
 20 
._c 
E o 
100 200 300 400 0 4 8 64 128 256 1200 
reinforcements prior context reinforcements 
Figure 2: Additional Autoshaping Data. A) Acquisition of keypecking. The figure shows response 
rate versus reinforcements. 6 The acquisition criterion is satisfied at a relatively early time when the 
response curve crosses the acquisition criterion line. B) The effects of prior context reinforcements on 
subsequent acquisition speed. The data are taken from two experiments, 1,2 with I/T= 6. 
predicted reward rate while the light is on is At + Ao, and the rate without the light 
is just Ao. 
The additive form of the model makes it similar to Rescorla-Wagner's 13 (RW) s- 
tandard delta-rule model, for which the net prediction of the expected reward in a 
trial is the sum of the associative values of each active predictor (in this case, the 
context and light). If the rewards are modeled as being just present or absent, the 
expected value for a reward is just its probability of occurrence. Instead, RET uses 
rates, which are just probabilities per unit time. 
GG 4 formulated their model from a frequentist viewpoint. However, it is easier to 
discuss a closely related Bayesian model which suffers from the same underlying 
problem. Instead of using RW's delta-rule for learning the rates, GG assume that 
reinforcements come from a constant rate Poisson process, and make sound statis- 
tical inferences about the rates given the data on the rewards. Using an improper 
flat prior over the rates, we can write the joint distribution as: 
7(AtA0 I data) vc 7(n]A1Aotlto) c (At + A0)e-(x*+xb)t*e 
(2) 
since all n rewards occur with the light, at rate At + A0. Here, tt = nT is the total 
time the light is on, and to = nI is the total time the light is off. 
GG take the further important step of relating the inferred rates At and A0 to the 
decision of the animals to start responding (ie to satisfy the acquisition criterion). 
GG suggest that acquisition should occur when the animals have strong evidence 
that the fractional increase in the reward rate, whilst the light is on, is greater than 
some threshold. More formally, acquisition should occur when: 
79((At + A0)/A0 > filn) = I- a 
(3) 
where ct is the uncertainty threshold and fi is slightly greater than one, reflect- 
ing the fractional increase. The n that first satisfies equation 3 can be found by 
integrating the joint probability in equation 2. It turns out that n oc tt/to, which 
has the approximate, linear dependence on the ratio I/T (as in figure lB), since 
h/to = nT/n! = T/I. It also has no dependence on partial reinforcement, as 
observed in figure 1C. 
However, even with a very low uncertainty, ct = 0.001, and a reasonable fractional 
increase, fi = 1.5, this model predicts that learning should be more than ten times 
as fast as observed, since we get n  20 � T/! as opposed to the 300 � T/I observed. 
20 50 
Equation 1 can only be satisfied by setting ct between 10- and 10- (depending 
on the precise values of I/T and fi)! This spells problems for GG as a normafive, 
ideal detector model of learning  it cannot, for instance, be repaired with any 
reasonable prior for the rates, as ct drops drastically with n. In other circumstances, 
A cquisia'on in 4utoshaping 2 7 
though, Gallistel, Mark & King 5 (forthcoming) have shown that animals can be 
ideal detectors of changes in rates. 
One hint of the flaw with GG is that simple manipulations to the context before 
starting autoshaping (in particular extinction) can produce very rapid learning. 2 
More generally, the data show that acquisition speed is stro
