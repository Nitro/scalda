OneLine Learning with Restricted 
Training Sets: 
Exact Solution as Benchmark 
for General Theories 
H.C. Rae 
hamish.rae@kcl.ac.uk 
P. Sollich 
psollich@mth.kcl.ac.uk 
Department of Mathematics 
King's College London 
The Strand 
London WC2R 2LS, UK 
A.C.C. Coolen 
tcoolen@mth.kcl.ac.uk 
Abstract 
We solve the dynamics of on-line Hebbian learning in perceptrons 
exactly, for the regime where the size of the training set scales 
linearly with the number of inputs. We consider both noiseless 
and noisy teachers. Our calculation cannot be extended to non- 
Hebbian rules, but the solution provides a nice benchmark to test 
more general and advanced theories for solving the dynamics of 
learning with restricted training sets. 
1 Introduction 
Considerable progress has been made in understanding the dynamics of supervised 
learning in layered neural networks through the application of the methods of sta- 
tistical mechanics. A recent review of work in this field is contained in [1]. For 
the most part, such theories have concentrated on systems where the training set is 
much larger than the number of updates. In such circumstances the probability that 
a question will be repeated during the training process is negligible and it is possible 
to assume for large networks, via the central limit theorem, that the local field dis- 
tribution is Gaussian. In this paper we consider restricted training sets; we suppose 
that the size of the training set scales linearly with N, the number of inputs. The 
probability that a question will reappear during the training process is no longer 
negligible, the assumption that the local fields have Gaussian distributions is not 
tenable, and it is clear that correlations will develop between the weights and the 
Learning with Restricted Training Sets.' Exact Solution 317 
questions in the training set as training progresses. In fact, the non-Gaussian char- 
acter of the local fields should be a prediction of any satisfactory theory of learning 
with restricted training sets, as this is clearly demanded by numerical simulations. 
Several authors [2, 3, 4, 5, 6, 7] have discussed learning with restricted training sets 
but a general theory is difficult. A simple model of learning with restricted training 
sets which can be solved exactly is therefore particularly attractive and provides 
a yardstick against which more difficult and sophisticated general theories can, in 
due course, be tested and compared. We show how this can be accomplished for 
on-line Hebbian learning in perceptrons with restricted training sets and we ob- 
tain exact solutions for the generalisation error and the training error for a class of 
noisy teachers and students with arbitrary weight decay. Our theory is in excellent 
agreement with numerical simulations and our prediction of the probability density 
of the student field is a striking confirmation of them, making it clear that we are 
indeed dealing with local fields which are non-Gaussian. 
2 Definitions 
We study on-line learning in a student perceptron $, which tries to perform a task 
defined by a teacher perceptron characterised by a fixed weight vector B* E RN. 
We assume, however, that the teacher is noisy and that the actual teacher output 
T and the corresponding student response S are given by 
T' {-1,1} N--> {-1,1} T() = sgn[B.], 
S' {-1,1} N {-1,1} S()= sgn[J.], 
where the vector B is drawn independently of  with probability p(B) which may 
depend explicitly on the correct teacher vector B*. Of particular interest are the 
following two choices, described in literature as output noise and Gaussian input 
noise, respectively: 
p(B) = A 5(B+B*) + (l-A) 5(B-B*) (1) 
where A _> 0 represents the probability that the teacher output is incorrect, and 
N 
p(B)= 2-- / e . (2) 
The variance E 2/.iV has been chosen so as to achieve appropriate scaling for N --> 
Our learning rule will be the on-line Hebbian rule, i.e. 
J(e+ 1) = (1 - )J(e) +  (e) sgn[B(e). (e)] (3) 
where the non-negative parameters 3' and r/are the decay rate and the learning rate, 
respectively. At each iteration step  an input vector (/) is picked at random from 
a training set consisting of p = cN randomly drawn vectors u E {-1, 1} :, / = 
1,...p. This set remains unchanged during the learning dynamics. At the same 
time the teacher selects at random, and independently of (), the vector B(f), 
according to the probability distribution p(B). Iterating equation (3) gives 
3' t/ I -  (e) sgn[B(e). (e)] (4) 
J(m)= 1- J0 +  =0 
We assume that the (noisy) teacher output is consistent in the sense that if a 
question  reappears at some stage during the training process the teacher makes 
the same choice of B in both cases, i.e. if () = (') then also B() = B('). This 
consistency allows us to define a generalised training set/) by including with the p 
318 H. C. Rae, P. Sollich and A. C. C. Coolen 
questions the corresponding teacher vectors: 
/5 = {(i,B),...,(P, BP)} 
There are two sources of randomness in this problem. First of all there is the random 
realisation of the 'path'  = {((0), B(0)), ((1), B(1)), ..., ((g), B(g)),...}. This 
is simply the randomness of the stochastic process that gives the evolution of the 
vector J. Averages over this process will be denoted as (...). Secondly there is the 
randomness in the composition of the training set. We will write averages over all 
training sets as (...)sets. We note that 
1 P 
(f[(g), B(t?)]) =  Z f(UBU (for all g) 
and that averages over all possible realisations of the training set are given by 
(f[(, B ), (2, B2),,,,, (v, Bp)])sets 
where { 6 {-1, 1} . We normalise B* so that [B*] 2 = 1 and choose the time unit 
t = miN. We finally assume that J0 and B* are statistically independent of the 
training vectors {, and that they obey &(0),B; = O(N-}) for all i. 
3 Explicit Microscopic Expressions 
At the m-th stage of the learning process the two simple scalar observables O[J] = 
j2 and R[J] = B* � J, and the joint distribution of fields x = J. , y = B* � , z = 
B �  (calculated over the questions in the training set/)), are given by 
O[J(m)] = j2(m) R[J(m)] = B* . J(m) (5) 
1 
e[x,y, z; a(,,)] =  y] [x - a(m) . ] [y - S* . ] [z - S .  ] (6) 
For infinitely large systems one can prove that the fluctuations in mean-field ob- 
servables such as {Q, R, P}, due to the randomness in the dynamics, will vanish [6]. 
Furthermore one assumes, with convincing support from numerical simulations, that 
for N %  the evolution of such observables, observed for different random realisa- 
tions of the training set, will be reproducible (i.e. the sample-to-sample fluctuations 
will also vanish, which is called 'self-averaging'). Both properties are central ingre- 
dients of all current theories. We are thus led to the introduction of the averages of 
the observables in (5,6), with respect to the dynamical randomness and with respect 
to the randomness in the training set (to be carried out in precisely this order)' 
q(t) = lira ( (q[a(tm)]))s,s a(t) = lim (([J(tN)]))ss (7) 
Pt(x,y,z) = lira ((P[x,y,z;J(tN)]))sets (8) 
N 
A fundamental ingredient of our calculations will be the average (i sgn(B.{))(, B), 
calculated over all realisations of ({, B). We find, for a wide class of p(B), that 
(gi sgn(B � =pm? + o(m -3/2) 
where, for example, 
Learning with Restricted Training Sets: Exact Solution 319 
p =  (1-2A) 
P= +E2 
(output noise) (10) 
(Gaussian input noise) 
(11) 
4 Averages of Simple Scalar Observables 
Calculation of Q(t) and R(t) using (4, 5, 7, 9) to execute the path average and the 
average over sets is relatively straightforward, albeit tedious. We find that 
e-'t (1 _ e-'t ) rl 2 
Q(t) = e-2VtOo + 2rlpRo + --ff(1--e -2vt) 
and that 
+ r/2 (1-e-Vt) 2 1 
(12) 
R(t) = e-VtRo + r/p7- (1 - e -vt) (13) 
where p is given by equations (10, 11) in the examples of output noise and Gaussian 
input noise, respectively. We note that the generalisation error is given by 
Eg 1 [ V/] 
= - arccos R(t)/ (14) 
All models of the teacher noise which have the same p will thus have the same 
generalisation error at any time. This is true, in particular, of output noise and 
Gaussian input noise when their respective parameters A and E are related by 
1 
1 - 2,X = (15) 
/1 + E 2 
With each type of teacher noise for which (9) holds, one can thus associate an 
effective output noise parameter A. Note, however, that this effective teacher error 
probability A will in general not be identical to the true teacher error probability 
associated with a given p(B), as can immediately be seen by calculating the latter 
for the Gaussian input noise (2). 
5 Average of the Joint Field Distribution 
The calculation of the average of the joint field distribution starting from equation 
(8) is more difficult. Writing cr = (1 -v/N), and expressing the 5 functions in terms 
of complex exponentials, we find that 
= f dd)di ei(x+yO+z)lim (e 
Pt(x,y,z) J 
x H  e -[iN-w-'(') sg (B')] (16) 
=0 u=l sets 
tN 
In this expression we replace  by  and B 1 by B, and abbreviate S = e=0['' ']' 
Upon writing the latter product in terms of the auxiliary variables v = (l .)/ 
and o: = B � , we find that for large N 
logs  X(: sgn[B. ],t) irl:u (1-e -*t) 
where u, u2 are the random variables given by 
7122U2 
4' 
(1 --e -2vt) (17) 
320 H. C. Rae, P. Sollich and A. C. C. Coolen 
i 1 
P v>l 
and with 
X(w, t) I f0  [e -['e'{-l - 1] 
= - ds (18) 
A study of the statistics of ui and u2 shows that limN,c u2 = 1, and that 
u = pB* �  + a-/2u (N  ), 
where u is a Gaussian random variable with mean equal to zero and variance unity. 
On the basis of these results and equations (16, 17) we find that 
8 3 
x lim (e -i[-J�'+B+B' (19) 
where Q and R are given by the expressions (12,13) (note: Q-R 2 is independent 
of p, i.e. of the distribution p(B)). Let x0 = J0', y = B*., z = B.. 

