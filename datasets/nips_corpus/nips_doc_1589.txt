Where does the population vector of motor 
cortical cells point during reaching movements? 
Pierre Baraduc* 
pbaraducgsnv. jussieu. fr 
Emmanuel Guigon 
guigon@ccr. jussieu. fr 
Yves Burnod 
ybteamgccr. jussieu. fr 
INSERM U483, Universit Pierre et Marie Curie 
9 quai St Bernard, 75252 Paris cedex 05, France 
Abstract 
Visually-guided arm reaching movements are produced by distributed 
neural networks within parietal and frontal regions of the cerebral cortex. 
Experimental data indicate that (1) single neurons in these regions are 
broadly tuned to parameters of movement; (2) appropriate commands are 
elaborated by populations of neurons; (3) the coordinated action of neu- 
rons can be visualized using a neuronal population vector (NPV). How- 
ever, the NPV provides only a rough estimate of movement parameters 
(direction, velocity) and may even fail to reflect the parameters of move- 
ment when arm posture is changed. We designed a model of the cortical 
motor command to investigate the relation between the desired direction 
of the movement, the actual direction of movement and the direction of 
the NPV in motor cortex. The model is a two-layer self-organizing neural 
network which combines broadly-tuned (muscular) proprioceptive and 
(cartesian) visual information to calculate (angular) motor commands for 
the initial part of the movement of a two-link arm. The network was 
trained by motor babbling in 5 positions. Simulations showed that (1) 
the network produced appropriate movement direction over a large part 
of the workspace; (2) small deviations of the actual trajectory from the 
desired trajectory existed at the extremities of the workspace; (3) these 
deviations were accompanied by large deviations of the NPV from both 
trajectories. These results suggest the NPV does not give a faithful image 
of cortical processing during arm reaching movements. 
* to whom correspondence should be addressed 
84 P Baraduc, E. Guigon and Y. Burnod 
1 INTRODUCTION 
When reaching to an object, our brain transforms a visual stimulus on the retina into a 
finely coordinated motor act. This complex process is subserved in part by distributed 
neuronal populations within parietal and frontal regions of the cerebral cortex (Kalaska 
and Crammond 1992). Neurons in these areas contribute to coordinate transformations 
by encoding target position and kinematic parameters of reaching movements in multi- 
ple frames of reference and to the elaboration of motor commands by sending directional 
and positional signals to the spinal cord (Georgopoulos 1996). An ubiquitous feature of 
cortical populations is that most neurons are broadly tuned to a preferred attribute (e.g. 
direction) and that tuning curves are uniformly (or regularly) distributed in the attribute 
space (Georgopoulos 1996). Accordingly, a powerful tool to analyse cortical populations 
is the NPV which describes the behavior of a whole population by a single vector (Geor- 
gopoulos 1996). Georgopoulos et al. (1986) have shown that the NPV calculated on a set 
of directionally tuned neurons in motor cortex points approximately (error  15 �) in the 
direction of movement. However, the NPV may fail to indicate the correct direction of 
movement when the arm is in a particular posture (Scott and Kalaska 1995). These data 
raise two important questions: (1) how populations of broadly tuned neurons learn to com- 
pute a correct sensorimotor transformation? Previous models (Burnod et al. 1992; Bullock 
et al. 1993; Salinas and Abbott 1995) provided partial solutions to this problem but we still 
lack a model which closely matches physiological and psychophysical data on reaching 
movements; (2) Are cortical processes involved in the visual guidance of arm movements 
readable with the NPV tool? This article provides answers to these questions through a 
physiologically inspired model of sensorimotor transformations. 
2 MODEL OF THE VISUAL-TO-MOTOR TRANSFORMATION 
2.1 ARM GEOMETRY 
The arm model has voluntarily been chosen simple. It is a planar, two-link arm, with 
limited (160 degrees)joint excursion at shoulder and elbow. An agonist/antagonist pair is 
attached at each joint. 
2.2 INPUT AND OUTPUT CODINGS 
No cell is finely tuned to a specific input or output value to mimic the broad tunings or 
monotonic firing characteristics found in cortical visuomotor areas. 
2.2.1 Arm position 
By analogy with the role of muscle spindles, proprioceptive sensors are assumed to code 
muscle length. Arm position is thus represented by the population activity of Nr = 20 
neurons coding for the length of each agonist or antagonist. The activity of a sensor neuron 
k is defined by: 
rk = ak(L,(k)) 
where L,() is the length of muscle number n(k), and ak a piecewise linear sigmoid: 
0 � L_<h 
a(L)= (L-Xk)/(Ak-X) � X <L<A 
1 � L>A 
Sensibility thresholds .&k are uniformly distributed in [Lrai, L,.x], and the dynamic range 
is Ak -  is taken constant, equal to Lraax - Lmin. 
Population Coding of Reaching Movements 85 
2.2.2 Desired direction 
The direction V of the desired movement in visual space is coded by a population of 
N: = 50 neurons with cosine tuning in cartesian space. Each visual neuron j thus fires as: 
xj = V. Vj 
Vj being the preferred direction of the cell. These 50 preferred directions are chosen 
uniformly distributed in 2-D space. 
2.2.3 Motor Command 
In attempt to model the existence of muscular synergies (Lemon 1988), we identified mo- 
tor command with joint movement rather than with muscle contraction. A motor neuron 
i among Nt = 50 contributes to the effective movement M by its action on a synergy 
(direction in joint space) Mi. This collective effect is formally expressed by: 
M-= E ti Mi 
i 
where ti is the activity of motor neuron i. The 50 directions of action Mi are supposed 
uniformly distributed in joint space. 
3 NETWORK STRUCTURE AND LEARNING 
3.1 STRUCTURE OF THE NETWORK 
Information concerning the position of the arm and the desired direction in cartesian space 
. ( direction 
motor synergy 
Figure 1: Network Architecture 
is combined asymmetrically (Fig. 1). First, an intermediate (somatic) layer of neurons 
86 P Baraduc, E. Guigon and Y. Burnod 
forms an internal representation of the arm position by a combination of the input from the 
Nr muscle sensors and the lateral interactions inside the population. Activity in this layer 
is expressed by: 
8ij -- E Wijk Tk q- E ljp Sip (1) 
k p 
where the lateral connections are: 
ljp -- COS( 2(j -- p)/Nr ) 
Equation 1 is self-referent; so calculation is done in two steps. The feed-forward input 
first arrives at time zero when there is no activity in the layer; iterated action of the lateral 
connections comes into play when this feed-forward input vanishes. 
The activity in the somatic layer is then combined with the visual directional information 
by the output sigma-pi neurons as follows: 
ti = E Xj 8ij 
3.2 WEIGHTS AND LEARNING 
The only adjustable weights are the wijk linking the proprioceptive layer to the somatic 
layer. Connectivity is random and not complete: only 15% of the somatic neurons receive 
information on arm position. The visuomotor mapping is learnt by modifying the internal 
representation of the arm. 
Motor commands issued by the network are correlated with the visual effect of the move- 
ment (motor babbling). More precisely, the learning algorithm is a repetition of the 
following cycle: 
1. choice of an arm position among 5 positions (stars on Fig. 2) 
2. random emission of a motor command (ti) 
3. corresponding visual reafference (xj) 
4. weight modification according to a variant of the delta rule: 
/Wijk (X (tixj -- 8ij) Tk 
The random commands arc gaussian distributions of activity over the output layer. 5000 
learning epochs arc sufficient to obtain a stabilized performance. It must be noted that 
the error between the ideal response of the network and the actual performance never de- 
creases completely to zero, as the constraints of the visuomotor transformation vary over 
the workspace. 
4 RESULTS 
4.1 NETWORK PERFORMANCE 
Correct learning of the mapping was tested in 21 positions in the workspace in a pointing 
task toward 16 uniformly distributed directions in cartesian space. Movement directions 
generated by the network are shown in Fig. 2 (desired direction 0 degree is shown bold). 
Norm of movement vectors depends on the global activity in the network which varies with 
arm position and movement direction. 
Performance of the network is maximal near the learning positions. However, a good gen- 
eralization is obtained (directional error 0.3 �, SD 12.1�); a bias toward the shoulder can be 
observed in extreme right or left positions. A similar effect was observed in psychophysical 
experiments (Ghilardi et al. 1995). 
Population Coding of Reaching Movements 87 
Figure 2: Performance in a pointing task 
4.2 PREFERRED DIRECTIONS AND POPULATION VECTOR 
4.2.1 Behavior of the population vector 
Preferred directions (PD) of output units were computed using a multilinear regression; 
a perfect cosine tuning was found, which is a consequence of the exact multiplication in 
sigma-pi neurons. Then, the population vector, the effective movement vector, and the 
desired movement were compared (Fig. 3) for two different arm configurations A and B 
marked on Fig. 2. The movement generated by the network (dashed arrow) is close to the 
poshon A position B ..... .. 
de,red drecton 
contnbution o! one neuron 
populabon vector 
actual movement ......... ..;> 
Figure 3: Actual movement and population vector in two arm positions 
desired one (dotted rays) for both arm configurations. However, the population vector (solid 
arrow) is not always aligned with the movement. The discrepancy between movement and 
population vector depends both on the direction and the position of the arm: it is maximal 
88 P. Baraduc, E. Guigon and Y. Burnod 
for positions near the borders of
